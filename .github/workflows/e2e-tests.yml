name: E2E Tests

on:
  push:
    branches: [master, main]
  pull_request:
    branches: [master, main]
  workflow_dispatch:  # Allow manual triggers

jobs:
  e2e:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: boss_workflow_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-asyncio pytest-cov pytest-timeout

      - name: Set up test environment
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/boss_workflow_test
          DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_BOSS_CHAT_ID: ${{ secrets.TELEGRAM_BOSS_CHAT_ID }}
        run: |
          # Set environment variables for tests
          echo "DATABASE_URL=$DATABASE_URL" >> $GITHUB_ENV
          echo "TESTING=true" >> $GITHUB_ENV
          echo "LOG_LEVEL=INFO" >> $GITHUB_ENV

      - name: Run database migrations
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/boss_workflow_test
        run: |
          # Run migrations if needed
          python -c "from src.database import init_db; import asyncio; asyncio.run(init_db())"

      - name: Run E2E tests
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/boss_workflow_test
          DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_BOSS_CHAT_ID: ${{ secrets.TELEGRAM_BOSS_CHAT_ID }}
        run: |
          pytest tests/e2e/ \
            -v \
            --tb=short \
            --cov=src \
            --cov-report=xml \
            --cov-report=term \
            --timeout=300 \
            --maxfail=3

      - name: Upload coverage reports
        uses: codecov/codecov-action@v3
        if: always()
        with:
          file: ./coverage.xml
          flags: e2e
          name: e2e-coverage

      - name: Upload test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: e2e-test-results
          path: |
            coverage.xml
            pytest-report.html

  e2e-smoke:
    runs-on: ubuntu-latest
    needs: e2e
    if: success()

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Run smoke tests (critical flows only)
        run: |
          pytest tests/e2e/test_critical_flows.py::TestTaskCreationFlows -v --tb=short

  e2e-performance:
    runs-on: ubuntu-latest
    needs: e2e
    if: github.event_name == 'push' && github.ref == 'refs/heads/master'

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Run performance tests
        run: |
          pytest tests/e2e/test_performance.py -v --tb=short

      - name: Performance regression check
        run: |
          # Check if performance baseline was exceeded
          pytest tests/e2e/test_performance.py::TestPerformanceRegression -v
